#!/usr/bin/env python3
"""
è¶…ç´§å‡‘äºŒè¿›åˆ¶ç¼–ç ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„ç¼–ç å™¨æ¥å‹ç¼©å’Œè§£å‹ç¿»è¯‘ç»“æœ
"""
import os
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.compact_encoder import (
    CompactBinaryEncoder, 
    encode_translation_data, 
    decode_translation_data, 
    get_compression_stats
)


def create_sample_translation_data():
    """åˆ›å»ºç¤ºä¾‹ç¿»è¯‘æ•°æ®"""
    return {
        "task_id": "550e8400-e29b-41d4-a716-446655440000",
        "task_type": "audio",
        "created_at": "2025-01-27T10:00:00Z",
        "completed_at": "2025-01-27T10:02:15Z",
        "accuracy": 0.95,
        "text_number": "123",
        "translations": {
            "en": {
                "AUDIO": {
                    "translated_text": "Hello, this is a transcribed and translated text from audio.",
                    "confidence": 0.95,
                    "source_type": "AUDIO",
                    "target_language": "en"
                },
                "TEXT": {
                    "translated_text": "Hello, this is a reference text for comparison.",
                    "confidence": 0.98,
                    "source_type": "TEXT",
                    "target_language": "en"
                }
            },
            "zh": {
                "AUDIO": {
                    "translated_text": "ä½ å¥½ï¼Œè¿™æ˜¯ä»éŸ³é¢‘è½¬å½•å’Œç¿»è¯‘çš„æ–‡æœ¬ã€‚",
                    "confidence": 0.92,
                    "source_type": "AUDIO",
                    "target_language": "zh"
                },
                "TEXT": {
                    "translated_text": "ä½ å¥½ï¼Œè¿™æ˜¯ç”¨äºæ¯”è¾ƒçš„å‚è€ƒæ–‡æœ¬ã€‚",
                    "confidence": 0.94,
                    "source_type": "TEXT",
                    "target_language": "zh"
                }
            },
            "ja": {
                "AUDIO": {
                    "translated_text": "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯éŸ³å£°ã‹ã‚‰è»¢å†™ãƒ»ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
                    "confidence": 0.89,
                    "source_type": "AUDIO",
                    "target_language": "ja"
                },
                "TEXT": {
                    "translated_text": "ã“ã‚“ã«ã¡ã¯ã€ã“ã‚Œã¯æ¯”è¼ƒç”¨ã®å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",
                    "confidence": 0.91,
                    "source_type": "TEXT",
                    "target_language": "ja"
                }
            }
        }
    }


def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    data = create_sample_translation_data()
    
    print("1. åŸå§‹æ•°æ®:")
    print(f"   ä»»åŠ¡ID: {data['task_id']}")
    print(f"   ä»»åŠ¡ç±»å‹: {data['task_type']}")
    print(f"   æ”¯æŒè¯­è¨€: {list(data['translations'].keys())}")
    
    # ç¼–ç 
    print("\n2. ç¼–ç ä¸ºè¶…ç´§å‡‘äºŒè¿›åˆ¶æ ¼å¼...")
    binary_data = encode_translation_data(data)
    print(f"   ç¼–ç å®Œæˆï¼Œå¤§å°: {len(binary_data)} bytes")
    
    # è§£ç 
    print("\n3. è§£ç äºŒè¿›åˆ¶æ•°æ®...")
    decoded_data = decode_translation_data(binary_data)
    print(f"   è§£ç å®Œæˆ")
    print(f"   ä»»åŠ¡ID: {decoded_data['task_id']}")
    print(f"   ä»»åŠ¡ç±»å‹: {decoded_data['task_type']}")
    print(f"   æ”¯æŒè¯­è¨€: {list(decoded_data['translations'].keys())}")
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print("\n4. éªŒè¯æ•°æ®å®Œæ•´æ€§...")
    assert decoded_data['task_type'] == data['task_type']
    assert decoded_data['accuracy'] == data['accuracy']
    assert len(decoded_data['translations']) == len(data['translations'])
    print("   âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")


def example_compression_analysis():
    """å‹ç¼©åˆ†æç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("å‹ç¼©åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    data = create_sample_translation_data()
    
    # è·å–å‹ç¼©ç»Ÿè®¡
    stats = get_compression_stats(data)
    
    print("å‹ç¼©ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  åŸå§‹å¤§å°: {stats['original_size']:,} bytes")
    print(f"  å‹ç¼©åå¤§å°: {stats['compressed_size']:,} bytes")
    print(f"  å‹ç¼©ç‡: {stats['compression_ratio']}")
    print(f"  èŠ‚çœç©ºé—´: {stats['size_reduction']:,} bytes")
    print(f"  ç¼–ç ç‰ˆæœ¬: {stats['encoding_version']}")
    
    # è®¡ç®—å­˜å‚¨æˆæœ¬èŠ‚çœï¼ˆå‡è®¾æ¯GBæ¯æœˆ$0.02ï¼‰
    gb_saved = stats['size_reduction'] / (1024 * 1024 * 1024)
    monthly_savings = gb_saved * 0.02
    print(f"\næˆæœ¬èŠ‚çœä¼°ç®—ï¼ˆæ¯ä¸ªæ–‡ä»¶ï¼‰:")
    print(f"  å­˜å‚¨ç©ºé—´èŠ‚çœ: {gb_saved * 1024:.2f} MB")
    print(f"  æœˆåº¦æˆæœ¬èŠ‚çœ: ${monthly_savings:.6f}")


def example_file_operations():
    """æ–‡ä»¶æ“ä½œç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("æ–‡ä»¶æ“ä½œç¤ºä¾‹")
    print("=" * 60)
    
    data = create_sample_translation_data()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜åŸå§‹JSONæ–‡ä»¶
    original_file = os.path.join(output_dir, "original.json")
    with open(original_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    # ç¼–ç å¹¶ä¿å­˜äºŒè¿›åˆ¶æ–‡ä»¶
    binary_file = os.path.join(output_dir, "compressed.bin")
    binary_data = encode_translation_data(data)
    with open(binary_file, 'wb') as f:
        f.write(binary_data)
    
    # ä»äºŒè¿›åˆ¶æ–‡ä»¶è§£ç å¹¶ä¿å­˜
    decoded_file = os.path.join(output_dir, "decoded.json")
    with open(binary_file, 'rb') as f:
        loaded_binary = f.read()
    
    decoded_data = decode_translation_data(loaded_binary)
    with open(decoded_file, 'w', encoding='utf-8') as f:
        json.dump(decoded_data, f, ensure_ascii=False, indent=2)
    
    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å¯¹æ¯”
    original_size = os.path.getsize(original_file)
    binary_size = os.path.getsize(binary_file)
    decoded_size = os.path.getsize(decoded_file)
    
    print("æ–‡ä»¶å¤§å°å¯¹æ¯”:")
    print(f"  åŸå§‹JSONæ–‡ä»¶: {original_size:,} bytes")
    print(f"  å‹ç¼©äºŒè¿›åˆ¶æ–‡ä»¶: {binary_size:,} bytes")
    print(f"  è§£ç JSONæ–‡ä»¶: {decoded_size:,} bytes")
    print(f"  å‹ç¼©ç‡: {(1 - binary_size / original_size) * 100:.1f}%")
    
    print(f"\næ–‡ä»¶å·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•:")
    print(f"  - {original_file}")
    print(f"  - {binary_file}")
    print(f"  - {decoded_file}")


def example_advanced_usage():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("é«˜çº§ä½¿ç”¨ç¤ºä¾‹ - è‡ªå®šä¹‰ç¼–ç å™¨")
    print("=" * 60)
    
    # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨å®ä¾‹
    encoder = CompactBinaryEncoder()
    
    data = create_sample_translation_data()
    
    # ç¼–ç 
    binary_data = encoder.encode(data)
    print(f"ç¼–ç å®Œæˆ: {len(binary_data)} bytes")
    
    # è§£ç 
    decoded_data = encoder.decode(binary_data)
    print("è§£ç å®Œæˆ")
    
    # è·å–è¯¦ç»†çš„ç¼–ç ä¿¡æ¯
    encoding_info = encoder.get_encoding_info(data)
    print("\nè¯¦ç»†ç¼–ç ä¿¡æ¯:")
    for key, value in encoding_info.items():
        print(f"  {key}: {value}")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("è¶…ç´§å‡‘äºŒè¿›åˆ¶ç¼–ç ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        example_basic_usage()
        example_compression_analysis()
        example_file_operations()
        example_advanced_usage()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())