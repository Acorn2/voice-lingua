# VoiceLingua 多语言转录翻译系统 - 开发设计文档

## 项目概述

**VoiceLingua** 是一个高性能、高可靠性的语音转录与多语言翻译系统，支持处理音频文件和文本输入，生成多语言翻译结果，并提供高效的任务管理和数据查询服务。系统采用微服务架构，基于 FastAPI、OpenAI Whisper 和 Celery 构建，使用异步任务队列和分布式架构，能够处理海量任务并确保高可靠性。

### 核心功能特性
- **智能语音转录 (STT)**：使用 OpenAI Whisper 将音频文件（MP3/WAV）转换为高质量文本
- **准确性校验**：基于参考文本使用 Levenshtein 距离算法校验 STT 结果准确性
- **多语言翻译**：支持英语、简体中文、繁体中文、日语等多种语言的并行翻译
- **智能任务管理**：支持任务创建、状态查询、取消操作，提供 RESTful API 接口
- **高效数据打包**：将多语言翻译结果打包为紧凑的 JSON 格式，支持快速查询
- **来源标记**：区分 AUDIO 和 TEXT 两种数据来源，便于追踪和管理
- **高可靠性**：支持任务重试、故障转移、内存监控和自动扩容

### 系统目标
- **高性能**：支持海量并发任务处理，单机支持 1000+ 并发转录任务
- **高可靠性**：确保零任务丢失，故障自动恢复，系统可用性 99.9%+
- **可扩展性**：支持水平扩展，根据负载自动调整资源
- **资源优化**：智能内存管理，避免 OutOfMemory 错误

## 系统架构设计

### 整体架构图
```
                    ┌─────────────────┐
                    │   用户界面      │
                    │  (可选前端)     │
                    └─────────┬───────┘
                              │
                    ┌─────────▼───────┐
                    │   API 网关      │
                    │   (FastAPI)     │
                    └─────────┬───────┘
                              │
              ┌───────────────┼───────────────┐
              │               │               │
    ┌─────────▼───────┐ ┌─────▼─────┐ ┌─────▼─────┐
    │  任务管理模块   │ │ 文件上传   │ │ 查询模块   │
    │               │ │ 模块       │ │           │
    └─────────┬─────┘ └─────┬─────┘ └─────┬─────┘
              │             │             │
              └─────────────┼─────────────┘
                            │
                  ┌─────────▼───────┐
                  │  Redis 消息队列  │
                  └─────────┬───────┘
                            │
              ┌─────────────┼─────────────┐
              │             │             │
    ┌─────────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐
    │ Celery Worker │ │ Celery    │ │ Celery    │
    │ (STT转录)     │ │ Worker    │ │ Worker    │
    │              │ │ (翻译)     │ │ (打包)     │
    └─────────┬─────┘ └─────┬─────┘ └─────┬─────┘
              │             │             │
              └─────────────┼─────────────┘
                            │
                  ┌─────────▼───────┐
                  │  PostgreSQL     │
                  │  (任务元数据)   │
                  └─────────┬───────┘
                            │
                  ┌─────────▼───────┐
                  │ 腾讯云COS存储   │
                  │ (文件&结果)     │
                  │ *推荐使用S3*    │
                  └─────────────────┘
```

### 核心组件详解

#### 1. API 层 (FastAPI)
- **职责**：提供 RESTful 接口，处理用户请求
- **特性**：异步处理、自动文档生成、数据验证
- **部署**：支持多实例负载均衡

#### 2. 任务队列 (Celery + Redis)
- **职责**：异步任务调度和执行
- **特性**：任务优先级、延迟执行、结果缓存
- **扩展性**：支持动态增减 Worker 节点

#### 3. 处理引擎
- **Whisper 转录引擎**：支持 GPU 加速，优先使用 CUDA
- **翻译引擎**：Hugging Face M2M100 或集成 LLM API
- **校验引擎**：Levenshtein 距离算法

#### 4. 存储系统
- **PostgreSQL**：存储任务元数据，支持 JSONB 字段
- **腾讯云COS**：存储音频、文本和结果文件（*建议使用S3兼容存储*）
- **Redis**：缓存热点数据和任务状态

#### 5. 监控系统
- **Prometheus**：指标收集
- **Grafana**：可视化监控面板
- **日志系统**：结构化日志记录

## 核心业务流程

### 1. 音频处理流程 (AUDIO 来源)

```
用户上传音频 → 创建任务(pending) → 文件上传COS → 触发STT转录
     ↓
Whisper转录 → 准确性校验 → 状态更新(processing) → 并行翻译任务
     ↓
多语言翻译(标记AUDIO) → 结果收集 → JSON打包 → 上传COS → 完成(completed)
```

**详细步骤**：
1. **任务创建阶段**
   - 接收音频文件（MP3/WAV）和可选参考文本
   - 生成唯一任务ID (UUID)
   - 存储任务元数据到 PostgreSQL（状态：`pending`）
   - 上传文件到腾讯云COS，记录文件路径

2. **STT 转录阶段**
   - Celery Worker 从 Redis 队列获取转录任务
   - 使用 Whisper 模型进行语音转录
   - 更新任务状态为 `processing`
   - 如果有参考文本，使用 Levenshtein 距离计算准确性分数

3. **并行翻译阶段**
   - 为每种目标语言创建独立的翻译任务
   - 并行执行翻译，来源标记为 `AUDIO`
   - 存储翻译结果到临时文件

4. **结果打包阶段**
   - 收集所有翻译结果
   - 生成标准化 JSON 格式文件
   - 上传到腾讯云COS永久存储
   - 更新任务状态为 `completed`

### 2. 文本处理流程 (TEXT 来源)

```
用户上传文本 → 创建任务(pending) → 文件上传COS → 并行翻译任务
     ↓
多语言翻译(标记TEXT) → 结果收集 → JSON打包 → 上传COS → 完成(completed)
```

**详细步骤**：
1. **任务创建**：接收文本文件，创建翻译任务
2. **并行翻译**：直接进行多语言翻译，标记来源为 `TEXT`
3. **结果打包**：生成 JSON 文件，包含原始文本和翻译结果

### 3. 查询流程

支持多维度查询：
- **按任务ID查询**：获取任务状态和完整结果
- **按语言+文本编号+来源查询**：快速检索特定翻译结果
- **批量查询**：支持批量获取多个翻译结果

## 技术选型与架构决策

### 编程语言与框架
- **Python 3.9+**：主要开发语言，与 AI 模型生态兼容性最佳
- **FastAPI**：现代异步 Web 框架，高性能、自动文档生成
- **Celery 5.4+**：成熟的分布式任务队列，支持复杂任务编排

### 核心依赖
- **OpenAI Whisper**：业界领先的语音转录模型
- **Hugging Face Transformers**：M2M100 多语言翻译模型
- **PyTorch**：深度学习框架，支持 GPU 加速
- **Textdistance**：文本相似度计算库

### 数据存储
- **PostgreSQL 14+**：主数据库，支持 JSONB 和复杂查询
- **Redis 6+**：消息队列和缓存，高性能键值存储
- **腾讯云COS**：对象存储，支持大文件和高并发访问（*建议优先考虑S3兼容存储*）

### 基础设施
- **Docker + Kubernetes**：容器化部署，支持自动扩缩容
- **NVIDIA GPU**：优先使用 GPU 加速 Whisper 模型推理
- **Prometheus + Grafana**：监控和告警系统

## 详细实现方案

### 1. 环境搭建与配置

#### Whisper 服务搭建
```bash
# 安装 GPU 版本 PyTorch
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118

# 安装 Whisper
pip install git+https://github.com/openai/whisper.git

# 验证 GPU 可用性
python -c "import torch; print(f'GPU可用: {torch.cuda.is_available()}, 设备数量: {torch.cuda.device_count()}')"

# 测试 Whisper 模型
python -c "import whisper; model = whisper.load_model('medium'); print('Whisper 模型加载成功')"
```

#### Docker 环境配置
```dockerfile
# Dockerfile
FROM nvidia/cuda:11.8-cudnn8-runtime-ubuntu20.04

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    python3 python3-pip ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# 设置工作目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .

# 安装 Python 依赖
RUN pip3 install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY src/ .

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. 核心 API 接口设计

#### 数据模型定义
```python
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum
import uuid

class TaskStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class SourceType(str, Enum):
    AUDIO = "AUDIO"
    TEXT = "TEXT"

class AudioTaskRequest(BaseModel):
    languages: List[str] = Field(..., description="目标翻译语言列表")
    reference_text: Optional[str] = Field(None, description="参考文本用于准确性校验")
    
class TextTaskRequest(BaseModel):
    languages: List[str] = Field(..., description="目标翻译语言列表")
    text_content: str = Field(..., description="待翻译的文本内容")

class TaskResponse(BaseModel):
    task_id: str
    status: TaskStatus
    created_at: str
    languages: List[str]
    accuracy: Optional[float] = None
    error_message: Optional[str] = None
    result_url: Optional[str] = None

class TranslationResult(BaseModel):
    task_id: str
    language: str
    text_id: str
    source: SourceType
    content: str
    accuracy: Optional[float] = None
```

#### 主要 API 端点
```python
from fastapi import FastAPI, File, UploadFile, HTTPException, Depends, Form
from fastapi.middleware.cors import CORSMiddleware
import logging
from typing import List, Dict, Any
import uuid
from datetime import datetime

app = FastAPI(
    title="VoiceLingua API",
    description="高性能语音转录与多语言翻译系统",
    version="1.0.0"
)

# 跨域配置
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 配置日志
logging.basicConfig(level=logging.INFO, filename="voicelingua.log", format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 引入其他模块的依赖
from tasks.transcription import transcribe_audio_task, save_transcription_result, get_task_by_id, update_task_status
from tasks.translation import translate_text_task, save_translation_result, get_all_translations_by_task, check_all_translations_completed
from tasks.packaging import package_results_task, upload_to_cos, get_task_id_by_text_id
from tasks.database import create_task_record, get_task_by_id, update_task_status, get_all_translations_by_task
from tasks.utils import save_uploaded_file

# 引入资源监控和重试管理
from tasks.resource_monitor import ResourceMonitor, check_resources_before_task, robust_task
from tasks.task_retry_manager import TaskRetryManager
from tasks.distributed_lock import DistributedLock, prevent_duplicate_task
from tasks.structured_logger import StructuredLogger, JsonFormatter
from tasks.metrics import start_metrics_server, TASK_COUNTER, TASK_DURATION, ACTIVE_TASKS, SYSTEM_MEMORY, SYSTEM_CPU, MetricsCollector

# 引入翻译查询服务
from typing import List
from tasks.translation_query_service import TranslationQueryService

# 引入 JSON 结果格式设计
from typing import Dict, Any

# 引入性能优化与最佳实践
from typing import List
from httpx import AsyncClient
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

# 引入测试与验证
import pytest
from unittest.mock import Mock, patch

# 引入依赖清单
from typing import List, Dict, Any

# 引入环境变量配置
from typing import Dict

# 引入总结
from typing import List


@app.on_event("startup")
async def startup_event():
    """应用启动时初始化"""
    logger.info("VoiceLingua API 启动")
    start_metrics_server()

@app.on_event("shutdown")
async def shutdown_event():
    """应用关闭时清理"""
    logger.info("VoiceLingua API 关闭")

@app.post("/api/v1/tasks/audio", response_model=TaskResponse)
async def create_audio_task(
    audio_file: UploadFile = File(..., description="音频文件 (MP3/WAV)"),
    languages: str = Form(..., description="目标语言列表，逗号分隔"),
    reference_text: Optional[str] = Form(None, description="参考文本")
):
    """
    创建音频转录与翻译任务
    
    支持的音频格式：MP3, WAV, M4A, FLAC
    支持的语言：en, zh, zh-tw, ja, ko, fr, de, es, it, ru
    """
    try:
        # 验证音频文件格式
        if not audio_file.filename.lower().endswith(('.mp3', '.wav', '.m4a', '.flac')):
            raise HTTPException(status_code=400, detail="不支持的音频格式")
        
        # 解析语言列表
        target_languages = [lang.strip() for lang in languages.split(',')]
        
        # 生成任务ID
        task_id = str(uuid.uuid4())
        
        # 保存文件到临时目录
        audio_path = await save_uploaded_file(audio_file, task_id)
        
        # 创建任务记录
        task = await create_task_record(
            task_id=task_id,
            task_type="audio",
            languages=target_languages,
            audio_file=audio_path,
            reference_text=reference_text
        )
        
        # 异步触发转录任务
        transcribe_audio_task.delay(task_id, audio_path, reference_text)
        
        logger.info(f"音频任务创建成功: {task_id}")
        
        return TaskResponse(
            task_id=task_id,
            status=TaskStatus.PENDING,
            created_at=task.created_at.isoformat(),
            languages=target_languages
        )
        
    except Exception as e:
        logger.error(f"创建音频任务失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"任务创建失败: {str(e)}")

@app.post("/api/v1/tasks/text", response_model=TaskResponse)
async def create_text_task(request: TextTaskRequest):
    """
    创建文本翻译任务
    
    直接翻译用户提供的文本内容
    """
    try:
        task_id = str(uuid.uuid4())
        
        # 创建任务记录
        task = await create_task_record(
            task_id=task_id,
            task_type="text",
            languages=request.languages,
            text_content=request.text_content
        )
        
        # 异步触发翻译任务
        for language in request.languages:
            translate_text_task.delay(task_id, request.text_content, language, SourceType.TEXT)
        
        logger.info(f"文本任务创建成功: {task_id}")
        
        return TaskResponse(
            task_id=task_id,
            status=TaskStatus.PENDING,
            created_at=task.created_at.isoformat(),
            languages=request.languages
        )
        
    except Exception as e:
        logger.error(f"创建文本任务失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"任务创建失败: {str(e)}")

@app.get("/api/v1/tasks/{task_id}", response_model=TaskResponse)
async def get_task_status(task_id: str):
    """
    查询任务状态和结果
    """
    try:
        task = await get_task_by_id(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="任务不存在")
        
        return TaskResponse(
            task_id=task.task_id,
            status=task.status,
            created_at=task.created_at.isoformat(),
            languages=task.languages,
            accuracy=task.accuracy,
            error_message=task.error_message,
            result_url=task.result_url
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"查询任务失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"查询失败: {str(e)}")

@app.delete("/api/v1/tasks/{task_id}")
async def cancel_task(task_id: str):
    """
    取消任务
    """
    try:
        success = await cancel_task_by_id(task_id)
        if not success:
            raise HTTPException(status_code=404, detail="任务不存在或无法取消")
        
        logger.info(f"任务已取消: {task_id}")
        return {"message": "任务已成功取消", "task_id": task_id}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"取消任务失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"取消失败: {str(e)}")

@app.get("/api/v1/translations/{language}/{text_id}/{source}", response_model=TranslationResult)
async def get_translation(language: str, text_id: str, source: SourceType):
    """
    按语言、文本编号和来源查询翻译结果
    
    这是系统要求的核心查询接口：通过 语言 -> 文本编号 -> 文本来源 快速查询
    """
    try:
        translation = await TranslationQueryService(cos_client, redis_client).query_translation(language, text_id, source)
        if not translation:
            raise HTTPException(status_code=404, detail="翻译结果不存在")
        
        return TranslationResult(
            task_id=translation["task_id"],
            language=translation["language"],
            text_id=translation["text_id"],
            source=SourceType(translation["source"]),
            content=translation["content"],
            accuracy=translation["confidence"]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"查询翻译失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"查询失败: {str(e)}")

@app.get("/api/v1/health")
async def health_check():
    """
    健康检查接口
    """
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }
```

### 3. Celery 异步任务实现

#### 任务配置
```python
from celery import Celery
from celery.signals import worker_ready
import psutil
import torch

# Celery 应用配置
celery_app = Celery(
    "voicelingua",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/1",
    include=['tasks.transcription', 'tasks.translation', 'tasks.packaging']
)

# 配置选项
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=30 * 60,  # 30分钟超时
    task_soft_time_limit=25 * 60,  # 25分钟软超时
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    worker_disable_rate_limits=True,
    task_default_retry_delay=60,
    task_max_retries=3,
)

# 路由配置
celery_app.conf.task_routes = {
    'tasks.transcription.*': {'queue': 'transcription'},
    'tasks.translation.*': {'queue': 'translation'},
    'tasks.packaging.*': {'queue': 'packaging'},
}

@worker_ready.connect
def worker_ready_handler(sender=None, **kwargs):
    """Worker 启动时的初始化"""
    logger.info(f"Worker 启动: {sender}")
    logger.info(f"GPU 可用: {torch.cuda.is_available()}")
    logger.info(f"系统内存: {psutil.virtual_memory().total / (1024**3):.1f} GB")
```

#### 转录任务
```python
import whisper
import torch
from textdistance import levenshtein
from celery import current_task

@celery_app.task(bind=True, name='tasks.transcription.transcribe_audio')
@robust_task(max_retries=3)
def transcribe_audio_task(self, task_id: str, audio_path: str, reference_text: str = None):
    """
    音频转录任务
    
    使用 Whisper 模型进行语音转文本，并计算准确性
    """
    try:
        # 内存检查
        memory_usage = psutil.virtual_memory().percent
        if memory_usage > 80:
            raise Exception(f"内存使用率过高: {memory_usage}%，暂停处理")
        
        # 更新任务状态
        update_task_status(task_id, TaskStatus.PROCESSING, {"message": "开始转录"})
        
        # 加载 Whisper 模型
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model("medium", device=device)
        
        # 执行转录
        logger.info(f"开始转录任务 {task_id}，使用设备: {device}")
        result = model.transcribe(
            audio_path,
            language="zh",  # 可以根据需要调整
            fp16=torch.cuda.is_available(),
            verbose=True
        )
        
        stt_text = result["text"].strip()
        confidence = result.get("confidence", 0.0)
        
        # 准确性校验
        accuracy_score = None
        if reference_text:
            accuracy_score = 1 - levenshtein.normalized_distance(stt_text, reference_text)
            logger.info(f"准确性分数: {accuracy_score:.3f}")
        
        # 保存转录结果
        stt_result = {
            "text": stt_text,
            "confidence": confidence,
            "accuracy": accuracy_score,
            "language": result.get("language", "zh")
        }
        
        save_transcription_result(task_id, stt_result)
        
        # 获取任务的目标语言
        task_info = get_task_by_id(task_id)
        target_languages = task_info.languages
        
        # 触发翻译任务
        for language in target_languages:
            translate_text_task.delay(task_id, stt_text, language, SourceType.AUDIO)
        
        # 如果有参考文本，也进行翻译
        if reference_text:
            for language in target_languages:
                translate_text_task.delay(task_id, reference_text, language, SourceType.TEXT)
        
        logger.info(f"转录任务完成: {task_id}")
        return {"status": "success", "text": stt_text, "accuracy": accuracy_score}
        
    except Exception as e:
        error_msg = f"转录失败: {str(e)}"
        logger.error(f"任务 {task_id} - {error_msg}")
        
        update_task_status(task_id, TaskStatus.FAILED, {"error": error_msg})
        
        # 重试逻辑
        if self.request.retries < self.max_retries:
            logger.info(f"重试转录任务 {task_id} (第 {self.request.retries + 1} 次)")
            raise self.retry(countdown=60, exc=e)
        
        raise e
```

#### 翻译任务
```python
from transformers import pipeline, M2M100ForConditionalGeneration, M2M100Tokenizer

# 语言映射
LANGUAGE_MAPPING = {
    "en": "en",
    "zh": "zh", 
    "zh-tw": "zh_TW",
    "ja": "ja",
    "ko": "ko",
    "fr": "fr",
    "de": "de",
    "es": "es",
    "it": "it",
    "ru": "ru"
}

@celery_app.task(bind=True, name='tasks.translation.translate_text')
@robust_task(max_retries=3)
def translate_text_task(self, task_id: str, text: str, target_language: str, source: SourceType):
    """
    文本翻译任务
    
    使用 M2M100 模型进行多语言翻译
    """
    try:
        # 内存检查
        memory_usage = psutil.virtual_memory().percent
        if memory_usage > 85:
            raise Exception(f"内存使用率过高: {memory_usage}%，暂停处理")
        
        # 跳过相同语言的翻译
        if target_language == "zh" and "中文" in text[:20]:
            logger.info(f"跳过相同语言翻译: {task_id} -> {target_language}")
            translated_text = text
        else:
            # 加载翻译模型
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            model_name = "facebook/m2m100_418M"
            tokenizer = M2M100Tokenizer.from_pretrained(model_name)
            model = M2M100ForConditionalGeneration.from_pretrained(model_name).to(device)
            
            # 设置源语言和目标语言
            tokenizer.src_lang = "zh"
            target_lang_code = LANGUAGE_MAPPING.get(target_language, target_language)
            
            # 执行翻译
            logger.info(f"开始翻译任务: {task_id} -> {target_language} ({source})")
            
            encoded = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
            generated_tokens = model.generate(
                **encoded,
                forced_bos_token_id=tokenizer.get_lang_id(target_lang_code),
                max_length=512,
                num_beams=4,
                early_stopping=True
            )
            
            translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
        
        # 保存翻译结果
        translation_result = {
            "task_id": task_id,
            "source_text": text,
            "translated_text": translated_text,
            "target_language": target_language,
            "source_type": source.value,
            "timestamp": datetime.utcnow().isoformat()
        }
        
        save_translation_result(task_id, target_language, source, translation_result)
        
        # 检查是否所有翻译都完成，触发打包任务
        if check_all_translations_completed(task_id):
            package_results_task.delay(task_id)
        
        logger.info(f"翻译任务完成: {task_id} -> {target_language} ({source})")
        return {"status": "success", "translated_text": translated_text}
        
    except Exception as e:
        error_msg = f"翻译失败: {str(e)}"
        logger.error(f"任务 {task_id} - {error_msg}")
        
        # 重试逻辑
        if self.request.retries < self.max_retries:
            logger.info(f"重试翻译任务 {task_id} (第 {self.request.retries + 1} 次)")
            raise self.retry(countdown=60, exc=e)
        
        raise e
```

#### 结果打包任务
```python
import json
from datetime import datetime

@celery_app.task(bind=True, name='tasks.packaging.package_results')
@robust_task(max_retries=3)
def package_results_task(self, task_id: str):
    """
    结果打包任务
    
    将所有翻译结果打包为 JSON 文件并上传到腾讯云COS
    """
    try:
        # 获取任务信息
        task_info = get_task_by_id(task_id)
        if not task_info:
            raise Exception(f"任务不存在: {task_id}")
        
        # 收集所有翻译结果
        translations = get_all_translations_by_task(task_id)
        
        # 构建结果数据结构
        result_data = {
            "task_id": task_id,
            "task_type": task_info.task_type,
            "created_at": task_info.created_at.isoformat(),
            "completed_at": datetime.utcnow().isoformat(),
            "accuracy": task_info.accuracy,
            "metadata": {
                "audio_duration": None, # 音频任务才有
                "audio_format": None,
                "model_version": None,
                "processing_time": None
            },
            "translations": {},
            "query_index": {
                "by_language": {},
                "by_source": {}
            }
        }

        # 填充 metadata (如果需要)
        if task_info.task_type == "audio":
            result_data["metadata"]["audio_duration"] = 180.5 # 示例值
            result_data["metadata"]["audio_format"] = "mp3"
            result_data["metadata"]["model_version"] = "whisper-medium"
            result_data["metadata"]["processing_time"] = 330.2 # 示例值

        # 按语言组织翻译结果
        for translation in translations:
            lang = translation.target_language
            source = translation.source_type
            
            if lang not in result_data["translations"]:
                result_data["translations"][lang] = {}
                result_data["query_index"]["by_language"][lang] = []
            
            # 根据来源确定键名
            key = "text" if source == SourceType.AUDIO else "reference_text"
            result_data["translations"][lang][key] = {
                "content": translation.translated_text,
                "source": source.value,
                "confidence": translation.confidence,
                "timestamp": translation.created_at.isoformat()
            }
            result_data["query_index"]["by_language"][lang].append(key)

            # 按来源组织
            if source.value not in result_data["query_index"]["by_source"]:
                result_data["query_index"]["by_source"][source.value] = {}
            
            if lang not in result_data["query_index"]["by_source"][source.value]:
                result_data["query_index"]["by_source"][source.value][lang] = []
            
            result_data["query_index"]["by_source"][source.value][lang].append(key)
        
        # 生成 JSON 文件
        json_filename = f"{task_id}.json"
        json_path = f"results/{json_filename}"
        
        # 本地保存
        local_path = f"temp/{json_filename}"
        os.makedirs("temp", exist_ok=True)
        
        with open(local_path, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # 上传到腾讯云COS
        cos_key = f"results/{task_id}/{json_filename}"
        upload_to_cos(local_path, cos_key)
        
        # 更新任务状态
        update_task_status(
            task_id, 
            TaskStatus.COMPLETED, 
            {"result_url": cos_key, "completed_at": datetime.utcnow().isoformat()}
        )
        
        # 清理临时文件
        os.remove(local_path)
        
        logger.info(f"打包任务完成: {task_id}")
        return {"status": "success", "result_url": cos_key}
        
    except Exception as e:
        error_msg = f"打包失败: {str(e)}"
        logger.error(f"任务 {task_id} - {error_msg}")
        
        update_task_status(task_id, TaskStatus.FAILED, {"error": error_msg})
        
        # 重试逻辑
        if self.request.retries < self.max_retries:
            logger.info(f"重试打包任务 {task_id} (第 {self.request.retries + 1} 次)")
            raise self.retry(countdown=60, exc=e)
        
        raise e
```

### 4. 数据库设计

#### PostgreSQL 表结构
```sql
-- 任务主表
CREATE TABLE tasks (
    task_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_type VARCHAR(20) NOT NULL, -- 'audio' 或 'text'
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    languages JSONB NOT NULL, -- 目标语言列表
    audio_file_path TEXT,
    text_content TEXT,
    reference_text TEXT,
    accuracy DECIMAL(5,4), -- STT 准确性分数
    error_message TEXT,
    result_url TEXT, -- 腾讯云COS结果文件路径
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE
);

-- 翻译结果表
CREATE TABLE translation_results (
    id SERIAL PRIMARY KEY,
    task_id UUID NOT NULL REFERENCES tasks(task_id) ON DELETE CASCADE,
    target_language VARCHAR(10) NOT NULL,
    source_type VARCHAR(10) NOT NULL, -- 'AUDIO' 或 'TEXT'
    source_text TEXT NOT NULL,
    translated_text TEXT NOT NULL,
    confidence DECIMAL(5,4),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- 创建唯一索引，支持快速查询
    UNIQUE(task_id, target_language, source_type)
);

-- 文本编号映射表 (支持按文本编号查询)
CREATE TABLE text_mappings (
    text_id VARCHAR(50) PRIMARY KEY, -- 业务文本编号
    task_id UUID NOT NULL REFERENCES tasks(task_id),
    language VARCHAR(10) NOT NULL,
    source_type VARCHAR(10) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- 创建索引优化查询性能
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_translation_results_lookup ON translation_results(target_language, source_type);
CREATE INDEX idx_text_mappings_lookup ON text_mappings(language, source_type);

-- 创建更新时间触发器
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_tasks_updated_at 
    BEFORE UPDATE ON tasks 
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### 5. 可靠性与扩展性设计

#### 内存监控与负载均衡
```python
import psutil
from typing import Dict, Any

class ResourceMonitor:
    """资源监控器"""
    
    def __init__(self, memory_threshold: float = 80.0, cpu_threshold: float = 90.0):
        self.memory_threshold = memory_threshold
        self.cpu_threshold = cpu_threshold
    
    def check_system_resources(self) -> Dict[str, Any]:
        """检查系统资源使用情况"""
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=1)
        disk = psutil.disk_usage('/')
        
        return {
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "threshold_exceeded": memory.percent > self.memory_threshold
            },
            "cpu": {
                "percent": cpu_percent,
                "threshold_exceeded": cpu_percent > self.cpu_threshold
            },
            "disk": {
                "total": disk.total,
                "free": disk.free,
                "percent": (disk.used / disk.total) * 100
            }
        }
    
    def should_accept_task(self) -> bool:
        """判断是否应该接受新任务"""
        resources = self.check_system_resources()
        
        if resources["memory"]["threshold_exceeded"]:
            logger.warning(f"内存使用率过高: {resources['memory']['percent']:.1f}%")
            return False
        
        if resources["cpu"]["threshold_exceeded"]:
            logger.warning(f"CPU使用率过高: {resources['cpu']['percent']:.1f}%")
            return False
        
        return True

# 在任务执行前检查资源
resource_monitor = ResourceMonitor()

def check_resources_before_task():
    """任务执行前的资源检查装饰器"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            if not resource_monitor.should_accept_task():
                raise Exception("系统资源不足，无法执行任务")
            return func(*args, **kwargs)
        return wrapper
    return decorator
```

#### 故障转移与重试机制
```python
from celery.exceptions import Retry
import time

class TaskRetryManager:
    """任务重试管理器"""
    
    @staticmethod
    def exponential_backoff(retry_count: int, base_delay: int = 60) -> int:
        """指数退避算法"""
        return min(base_delay * (2 ** retry_count), 300)  # 最大5分钟
    
    @staticmethod
    def should_retry(exception: Exception, retry_count: int, max_retries: int = 3) -> bool:
        """判断是否应该重试"""
        # 不重试的异常类型
        non_retryable_exceptions = (
            ValueError,  # 参数错误
            FileNotFoundError,  # 文件不存在
            PermissionError,  # 权限错误
        )
        
        if isinstance(exception, non_retryable_exceptions):
            return False
        
        if retry_count >= max_retries:
            return False
        
        return True

# 增强的任务装饰器
def robust_task(max_retries=3, default_retry_delay=60):
    """健壮的任务装饰器，包含重试和错误处理"""
    def decorator(func):
        @celery_app.task(bind=True, max_retries=max_retries)
        @check_resources_before_task()
        def wrapper(self, *args, **kwargs):
            try:
                return func(self, *args, **kwargs)
            except Exception as e:
                retry_count = self.request.retries
                
                if TaskRetryManager.should_retry(e, retry_count, max_retries):
                    delay = TaskRetryManager.exponential_backoff(retry_count, default_retry_delay)
                    logger.warning(f"任务失败，{delay}秒后重试 (第{retry_count + 1}次): {str(e)}")
                    raise self.retry(countdown=delay, exc=e)
                else:
                    logger.error(f"任务最终失败，停止重试: {str(e)}")
                    raise e
        
        return wrapper
    return decorator
```

#### 分布式锁与任务去重
```python
import redis
import uuid
from contextlib import contextmanager

class DistributedLock:
    """分布式锁，防止重复任务"""
    
    def __init__(self, redis_client: redis.Redis, key: str, timeout: int = 60):
        self.redis_client = redis_client
        self.key = f"lock:{key}"
        self.timeout = timeout
        self.identifier = str(uuid.uuid4())
    
    @contextmanager
    def acquire(self):
        """获取锁的上下文管理器"""
        try:
            if self._acquire():
                yield
            else:
                raise Exception(f"无法获取锁: {self.key}")
        finally:
            self._release()
    
    def _acquire(self) -> bool:
        """获取锁"""
        return self.redis_client.set(
            self.key, 
            self.identifier, 
            nx=True, 
            ex=self.timeout
        )
    
    def _release(self) -> bool:
        """释放锁"""
        script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        return self.redis_client.eval(script, 1, self.key, self.identifier)

# 防重复任务装饰器
def prevent_duplicate_task(lock_key_func):
    """防止重复任务的装饰器"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            lock_key = lock_key_func(*args, **kwargs)
            lock = DistributedLock(redis_client, lock_key)
            
            with lock.acquire():
                return func(*args, **kwargs)
        
        return wrapper
    return decorator

# 使用示例
@prevent_duplicate_task(lambda task_id, *args: f"transcribe:{task_id}")
@robust_task(max_retries=3)
def transcribe_audio_task(self, task_id: str, audio_path: str, reference_text: str = None):
    # 转录任务实现
    pass
```

### 6. 监控与日志系统

#### 结构化日志配置
```python
import logging
import json
from datetime import datetime
from typing import Dict, Any

class StructuredLogger:
    """结构化日志记录器"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # 文件处理器
        file_handler = logging.FileHandler('voicelingua.log', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # JSON 格式化器
        formatter = JsonFormatter()
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def log_task_event(self, task_id: str, event: str, **kwargs):
        """记录任务事件"""
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "task_id": task_id,
            "event": event,
            **kwargs
        }
        self.logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def log_error(self, task_id: str, error: Exception, **kwargs):
        """记录错误"""
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "task_id": task_id,
            "level": "ERROR",
            "error_type": type(error).__name__,
            "error_message": str(error),
            **kwargs
        }
        self.logger.error(json.dumps(log_data, ensure_ascii=False))

class JsonFormatter(logging.Formatter):
    """JSON 日志格式化器"""
    
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcfromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
        }
        
        if hasattr(record, 'task_id'):
            log_data["task_id"] = record.task_id
        
        return json.dumps(log_data, ensure_ascii=False)

# 全局日志记录器
app_logger = StructuredLogger("voicelingua")
```

#### Prometheus 监控指标
```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# 定义监控指标
TASK_COUNTER = Counter('voicelingua_tasks_total', 'Total number of tasks', ['task_type', 'status'])
TASK_DURATION = Histogram('voicelingua_task_duration_seconds', 'Task duration', ['task_type'])
ACTIVE_TASKS = Gauge('voicelingua_active_tasks', 'Number of active tasks')
SYSTEM_MEMORY = Gauge('voicelingua_memory_usage_percent', 'Memory usage percentage')
SYSTEM_CPU = Gauge('voicelingua_cpu_usage_percent', 'CPU usage percentage')

class MetricsCollector:
    """指标收集器"""
    
    def __init__(self):
        self.start_time = {}
    
    def start_task_timing(self, task_id: str, task_type: str):
        """开始任务计时"""
        self.start_time[task_id] = time.time()
        ACTIVE_TASKS.inc()
    
    def end_task_timing(self, task_id: str, task_type: str, status: str):
        """结束任务计时"""
        if task_id in self.start_time:
            duration = time.time() - self.start_time[task_id]
            TASK_DURATION.labels(task_type=task_type).observe(duration)
            del self.start_time[task_id]
        
        TASK_COUNTER.labels(task_type=task_type, status=status).inc()
        ACTIVE_TASKS.dec()
    
    def update_system_metrics(self):
        """更新系统指标"""
        memory = psutil.virtual_memory()
        cpu = psutil.cpu_percent()
        
        SYSTEM_MEMORY.set(memory.percent)
        SYSTEM_CPU.set(cpu)

# 全局指标收集器
metrics_collector = MetricsCollector()

# 启动 Prometheus 指标服务器
def start_metrics_server(port: int = 8001):
    """启动指标服务器"""
    start_http_server(port)
    logger.info(f"Prometheus 指标服务器启动在端口 {port}")
```

### 7. 部署配置

#### Docker Compose 配置
```yaml
# docker-compose.yml
version: '3.8'

services:
  # API 服务
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
      - COS_BUCKET=voicelingua-storage
      - TENCENT_SECRET_ID=${TENCENT_SECRET_ID}
      - TENCENT_SECRET_KEY=${TENCENT_SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Workers
  worker-transcription:
    build: .
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
      - COS_BUCKET=voicelingua-storage
      - TENCENT_SECRET_ID=${TENCENT_SECRET_ID}
      - TENCENT_SECRET_KEY=${TENCENT_SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    command: celery -A main worker --loglevel=info --queues=transcription --concurrency=2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  worker-translation:
    build: .
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
      - COS_BUCKET=voicelingua-storage
      - TENCENT_SECRET_ID=${TENCENT_SECRET_ID}
      - TENCENT_SECRET_KEY=${TENCENT_SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    command: celery -A main worker --loglevel=info --queues=translation --concurrency=4
    scale: 2

  worker-packaging:
    build: .
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
      - COS_BUCKET=voicelingua-storage
      - TENCENT_SECRET_ID=${TENCENT_SECRET_ID}
      - TENCENT_SECRET_KEY=${TENCENT_SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    command: celery -A main worker --loglevel=info --queues=packaging --concurrency=2

  # 数据库
  db:
    image: postgres:14
    environment:
      POSTGRES_DB: voicelingua
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"

  # Redis
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # 监控
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

#### Kubernetes 部署配置
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: voicelingua-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: voicelingua-api
  template:
    metadata:
      labels:
        app: voicelingua-api
    spec:
      containers:
      - name: api
        image: voicelingua:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: voicelingua-secrets
              key: database-url
        - name: REDIS_URL
          value: "redis://redis-service:6379/0"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/v1/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/v1/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: voicelingua-worker-gpu
spec:
  replicas: 2
  selector:
    matchLabels:
      app: voicelingua-worker-gpu
  template:
    metadata:
      labels:
        app: voicelingua-worker-gpu
    spec:
      containers:
      - name: worker
        image: voicelingua:latest
        command: ["celery", "-A", "main", "worker", "--loglevel=info", "--queues=transcription", "--concurrency=1"]
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: voicelingua-secrets
              key: database-url
        - name: REDIS_URL
          value: "redis://redis-service:6379/0"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
            nvidia.com/gpu: 1
          limits:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: 1

---
apiVersion: v1
kind: Service
metadata:
  name: voicelingua-api-service
spec:
  selector:
    app: voicelingua-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: voicelingua-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: voicelingua-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## 高效数据打包方案

### JSON 结果格式设计
```json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "task_type": "audio",
  "created_at": "2024-01-01T10:00:00Z",
  "completed_at": "2024-01-01T10:05:30Z",
  "accuracy": 0.95,
  "metadata": {
    "audio_duration": 180.5,
    "audio_format": "mp3",
    "model_version": "whisper-medium",
    "processing_time": 330.2
  },
  "translations": {
    "en": {
      "text": {
        "content": "Hello, this is a transcribed text from audio.",
        "source": "AUDIO",
        "confidence": 0.92,
        "timestamp": "2024-01-01T10:02:15Z"
      },
      "reference_text": {
        "content": "Hello, this is the reference text provided.",
        "source": "TEXT",
        "timestamp": "2024-01-01T10:03:20Z"
      }
    },
    "zh": {
      "text": {
        "content": "你好，这是从音频转录的文本。",
        "source": "AUDIO",
        "confidence": 0.94,
        "timestamp": "2024-01-01T10:02:25Z"
      },
      "reference_text": {
        "content": "你好，这是提供的参考文本。",
        "source": "TEXT",
        "timestamp": "2024-01-01T10:03:30Z"
      }
    },
    "ja": {
      "text": {
        "content": "こんにちは、これは音声から転写されたテキストです。",
        "source": "AUDIO",
        "confidence": 0.89,
        "timestamp": "2024-01-01T10:02:35Z"
      }
    }
  },
  "query_index": {
    "by_language": {
      "en": ["text", "reference_text"],
      "zh": ["text", "reference_text"],
      "ja": ["text"]
    },
    "by_source": {
      "AUDIO": {
        "en": "text",
        "zh": "text", 
        "ja": "text"
      },
      "TEXT": {
        "en": "reference_text",
        "zh": "reference_text"
      }
    }
  }
}
```

### 快速查询接口实现
```python
class TranslationQueryService:
    """翻译查询服务"""
    
    def __init__(self, cos_client, redis_client):
        self.cos_client = cos_client
        self.redis_client = redis_client
        self.cache_ttl = 3600  # 1小时缓存
    
    async def query_translation(self, language: str, text_id: str, source: SourceType) -> Dict[str, Any]:
        """
        按 语言 -> 文本编号 -> 文本来源 查询翻译结果
        
        这是系统设计要求的核心查询功能
        """
        # 构建缓存键
        cache_key = f"translation:{language}:{text_id}:{source.value}"
        
        # 尝试从缓存获取
        cached_result = self.redis_client.get(cache_key)
        if cached_result:
            return json.loads(cached_result)
        
        # 从数据库查询任务ID
        task_id = await self.get_task_id_by_text_id(text_id)
        if not task_id:
            raise ValueError(f"文本编号不存在: {text_id}")
        
        # 从腾讯云COS获取完整结果文件
        result_data = await self.get_result_from_cos(task_id)
        
        # 提取指定的翻译结果
        translation = self.extract_translation(result_data, language, source)
        
        # 缓存结果
        self.redis_client.setex(
            cache_key, 
            self.cache_ttl, 
            json.dumps(translation, ensure_ascii=False)
        )
        
        return translation
    
    def extract_translation(self, result_data: Dict, language: str, source: SourceType) -> Dict[str, Any]:
        """从结果数据中提取指定翻译"""
        translations = result_data.get("translations", {})
        lang_data = translations.get(language, {})
        
        # 根据来源确定键名
        key = "text" if source == SourceType.AUDIO else "reference_text"
        
        translation_data = lang_data.get(key)
        if not translation_data:
            raise ValueError(f"翻译结果不存在: {language}/{source.value}")
        
        return {
            "task_id": result_data["task_id"],
            "language": language,
            "source": source.value,
            "content": translation_data["content"],
            "confidence": translation_data.get("confidence"),
            "timestamp": translation_data["timestamp"]
        }
    
    async def batch_query_translations(self, queries: List[Dict]) -> List[Dict]:
        """批量查询翻译结果"""
        results = []
        
        for query in queries:
            try:
                result = await self.query_translation(
                    query["language"],
                    query["text_id"], 
                    SourceType(query["source"])
                )
                results.append(result)
            except Exception as e:
                results.append({"error": str(e), "query": query})
        
        return results
```

## 性能优化与最佳实践

### 1. 内存管理策略
- **模型延迟加载**：仅在需要时加载 Whisper 和翻译模型
- **模型共享**：多个 Worker 共享同一个模型实例
- **内存监控**：实时监控内存使用，超过阈值时拒绝新任务
- **垃圾回收**：定期清理临时文件和缓存

### 2. 并发处理优化
- **队列分离**：转录、翻译、打包使用不同队列
- **优先级调度**：紧急任务优先处理
- **资源隔离**：GPU 任务和 CPU 任务分离部署

### 3. 缓存策略
- **Redis 缓存**：常用翻译结果缓存 1 小时
- **CDN 加速**：腾讯云COS文件通过CDN加速访问
- **数据库连接池**：优化数据库连接性能

### 4. 错误处理与恢复
- **熔断机制**：服务异常时自动熔断保护
- **优雅降级**：关键服务不可用时的降级策略
- **数据备份**：定期备份重要数据到多个存储位置

## 测试与验证

### 1. 单元测试
```python
import pytest
from unittest.mock import Mock, patch
from tasks.transcription import transcribe_audio_task

class TestTranscriptionTask:
    
    @patch('tasks.transcription.whisper.load_model')
    @patch('tasks.transcription.psutil.virtual_memory')
    def test_transcribe_audio_success(self, mock_memory, mock_model):
        """测试音频转录成功"""
        # 模拟内存正常
        mock_memory.return_value.percent = 50.0
        
        # 模拟 Whisper 模型
        mock_whisper = Mock()
        mock_whisper.transcribe.return_value = {
            "text": "测试转录文本",
            "confidence": 0.95,
            "language": "zh"
        }
        mock_model.return_value = mock_whisper
        
        # 执行测试
        result = transcribe_audio_task.apply(
            args=("test_task_id", "test_audio.mp3", "参考文本")
        )
        
        assert result.successful()
        assert "测试转录文本" in str(result.result)
    
    @patch('tasks.transcription.psutil.virtual_memory')
    def test_transcribe_memory_limit(self, mock_memory):
        """测试内存不足时的处理"""
        # 模拟内存不足
        mock_memory.return_value.percent = 85.0
        
        with pytest.raises(Exception) as exc_info:
            transcribe_audio_task.apply(
                args=("test_task_id", "test_audio.mp3", None)
            )
        
        assert "内存使用率过高" in str(exc_info.value)
```

### 2. 集成测试
```python
import asyncio
from httpx import AsyncClient
from main import app

class TestAPIIntegration:
    
    @pytest.mark.asyncio
    async def test_full_audio_workflow(self):
        """测试完整的音频处理流程"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            # 1. 上传音频文件
            with open("test_audio.mp3", "rb") as audio_file:
                response = await client.post(
                    "/api/v1/tasks/audio",
                    files={"audio_file": audio_file},
                    data={"languages": "en,zh,ja"}
                )
            
            assert response.status_code == 200
            task_data = response.json()
            task_id = task_data["task_id"]
            
            # 2. 等待任务完成
            for _ in range(30):  # 最多等待30秒
                response = await client.get(f"/api/v1/tasks/{task_id}")
                task_status = response.json()
                
                if task_status["status"] == "completed":
                    break
                elif task_status["status"] == "failed":
                    pytest.fail(f"任务失败: {task_status.get('error_message')}")
                
                await asyncio.sleep(1)
            
            # 3. 验证结果
            assert task_status["status"] == "completed"
            assert "result_url" in task_status
            
            # 4. 查询翻译结果
            response = await client.get(f"/api/v1/translations/en/{task_id}/AUDIO")
            assert response.status_code == 200
            
            translation = response.json()
            assert translation["language"] == "en"
            assert translation["source"] == "AUDIO"
            assert len(translation["content"]) > 0
```

### 3. 性能测试
```python
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

async def performance_test_concurrent_tasks(num_tasks: int = 100):
    """测试并发任务处理性能"""
    start_time = time.time()
    
    # 创建并发任务
    tasks = []
    async with AsyncClient(app=app, base_url="http://test") as client:
        for i in range(num_tasks):
            task = client.post(
                "/api/v1/tasks/text",
                json={
                    "languages": ["en", "ja"],
                    "text_content": f"测试文本 {i}"
                }
            )
            tasks.append(task)
        
        # 等待所有任务创建完成
        responses = await asyncio.gather(*tasks)
    
    # 验证所有任务都成功创建
    successful_tasks = sum(1 for r in responses if r.status_code == 200)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"创建 {num_tasks} 个任务耗时: {duration:.2f} 秒")
    print(f"成功率: {successful_tasks/num_tasks*100:.1f}%")
    print(f"平均每秒处理: {num_tasks/duration:.1f} 个任务")
    
    assert successful_tasks >= num_tasks * 0.95  # 至少95%成功率
```

## 部署与运维指南

### 1. 生产环境部署清单
- [ ] 配置 GPU 节点和驱动
- [ ] 设置腾讯云COS存储桶和访问权限
- [ ] 配置 PostgreSQL 数据库和备份策略
- [ ] 部署 Redis 集群
- [ ] 设置 Prometheus 和 Grafana 监控
- [ ] 配置日志收集和分析
- [ ] 设置 SSL 证书和域名
- [ ] 配置负载均衡器
- [ ] 设置自动扩缩容策略
- [ ] 配置灾备和故障恢复

### 2. 运维监控要点
- **关键指标**：任务成功率、处理延迟、系统资源使用率
- **告警规则**：任务失败率 > 5%、内存使用率 > 90%、磁盘空间 < 10%
- **定期任务**：日志清理、临时文件清理、数据库优化
- **性能调优**：根据负载调整 Worker 数量、优化模型参数

### 3. 故障排查指南
```bash
# 检查系统状态
kubectl get pods -n voicelingua
docker-compose ps

# 查看任务队列状态
celery -A main inspect active
celery -A main inspect stats

# 检查数据库连接
psql -h localhost -U postgres -d voicelingua -c "SELECT COUNT(*) FROM tasks;"

# 查看错误日志
tail -f logs/voicelingua.log | grep ERROR
kubectl logs -f deployment/voicelingua-api

# 监控系统资源
htop
nvidia-smi
df -h
```

## 完整依赖清单

### requirements.txt
```txt
# Web 框架
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# 异步任务
celery[redis]==5.3.4
redis==5.0.1

# 数据库
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.12.1

# AI 模型
openai-whisper==20231117
torch==2.1.1
torchvision==0.16.1
torchaudio==2.1.1
transformers==4.35.2
sentence-transformers==2.2.2

# 文本处理
textdistance==4.6.1
jieba==0.42.1
langdetect==1.0.9

# 存储和网络
boto3==1.34.0
botocore==1.34.0
httpx==0.25.2

# 系统监控
psutil==5.9.6
prometheus-client==0.19.0

# 工具库
pydantic==2.5.0
python-dotenv==1.0.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# 开发和测试
pytest==7.4.3
pytest-asyncio==0.21.1
black==23.11.0
isort==5.12.0
mypy==1.7.1
```

### 环境变量配置 (.env)
```bash
# 数据库配置
DATABASE_URL=postgresql://postgres:password@localhost:5432/voicelingua
POSTGRES_DB=voicelingua
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password

# Redis 配置
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# 腾讯云COS存储配置（建议使用S3兼容存储）
TENCENT_SECRET_ID=your_secret_id
TENCENT_SECRET_KEY=your_secret_key
TENCENT_COS_REGION=ap-beijing
COS_BUCKET_NAME=voicelingua-storage

# 应用配置
APP_NAME=VoiceLingua
APP_VERSION=1.0.0
DEBUG=false
SECRET_KEY=your_super_secure_secret_key_here

# Whisper 配置
WHISPER_MODEL=medium
WHISPER_DEVICE=cuda  # 或 cpu
WHISPER_LANGUAGE=zh

# 翻译配置
TRANSLATION_MODEL=facebook/m2m100_418M
MAX_TRANSLATION_LENGTH=512

# 系统限制
MAX_UPLOAD_SIZE=100MB
MAX_CONCURRENT_TASKS=10
MEMORY_THRESHOLD=80
CPU_THRESHOLD=90

# 监控配置
PROMETHEUS_PORT=8001
LOG_LEVEL=INFO
LOG_FILE=logs/voicelingua.log

# 安全配置
ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com
CORS_ORIGINS=http://localhost:3000,https://your-frontend.com
```

## 总结

本设计文档详细描述了 VoiceLingua 系统的完整实现方案，包括：

1. **完整的业务流程**：音频转录、文本翻译、结果打包和查询
2. **可靠的技术架构**：微服务设计、异步处理、分布式存储
3. **高性能实现**：GPU 加速、并行处理、智能缓存
4. **企业级可靠性**：故障转移、任务重试、监控告警
5. **可扩展性设计**：水平扩展、资源监控、自动调度

系统设计充分考虑了题目要求的所有核心功能：
- ✅ Whisper 语音转录服务（GPU 优化）
- ✅ STT 准确性校验（Levenshtein 距离）
- ✅ 多语言翻译（英语、中文、日语等）
- ✅ 高效数据打包（JSON 格式）
- ✅ 快速查询接口（语言→文本编号→来源）
- ✅ 海量任务处理（Celery + Redis）
- ✅ 内存监控和 OOM 防护
- ✅ 故障转移和任务重试
- ✅ 完整的错误处理和日志记录

该系统能够满足高并发、高可靠性的生产环境需求，支持水平扩展和故障恢复，为用户提供稳定高效的语音转录和翻译服务。