# VoiceLingua 多语言转录翻译系统 - 开发设计文档

## 项目概述

**VoiceLingua** 是一个高性能、高可靠性的语音转录与多语言翻译系统，支持处理音频文件和文本输入，生成多语言翻译结果，并提供高效的任务管理和数据查询服务。系统采用微服务架构，基于 FastAPI、OpenAI Whisper 和 Celery 构建，使用异步任务队列和分布式架构，能够处理海量任务并确保高可靠性。

### 核心功能特性
- **智能语音转录 (STT)**：使用 OpenAI Whisper 将音频文件（MP3/WAV）转换为高质量文本
- **准确性校验**：基于参考文本使用 Levenshtein 距离算法校验 STT 结果准确性
- **多语言翻译**：支持英语、简体中文、繁体中文、日语等多种语言的并行翻译
- **智能任务管理**：支持任务创建、状态查询、取消操作，提供 RESTful API 接口
- **高效数据打包**：将多语言翻译结果打包为紧凑的 JSON 格式，支持快速查询
- **来源标记**：区分 AUDIO 和 TEXT 两种数据来源，便于追踪和管理
- **高可靠性**：支持任务重试、故障转移、内存监控和自动扩容

### 系统目标
- **高性能**：支持海量并发任务处理，单机支持 1000+ 并发转录任务
- **高可靠性**：确保零任务丢失，故障自动恢复，系统可用性 99.9%+
- **可扩展性**：支持水平扩展，根据负载自动调整资源
- **资源优化**：智能内存管理，避免 OutOfMemory 错误

## 系统架构设计

### 整体架构图
```
                    ┌─────────────────┐
                    │   用户界面      │
                    │  (可选前端)     │
                    └─────────┬───────┘
                              │
                    ┌─────────▼───────┐
                    │   API 网关      │
                    │   (FastAPI)     │
                    └─────────┬───────┘
                              │
              ┌───────────────┼───────────────┐
              │               │               │
    ┌─────────▼───────┐ ┌─────▼─────┐ ┌─────▼─────┐
    │  任务管理模块   │ │ 文件上传   │ │ 查询模块   │
    │               │ │ 模块       │ │           │
    └─────────┬─────┘ └─────┬─────┘ └─────┬─────┘
              │             │             │
              └─────────────┼─────────────┘
                            │
                  ┌─────────▼───────┐
                  │  Redis 消息队列  │
                  └─────────┬───────┘
                            │
              ┌─────────────┼─────────────┐
              │             │             │
    ┌─────────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐
    │ Celery Worker │ │ Celery    │ │ Celery    │
    │ (STT转录)     │ │ Worker    │ │ Worker    │
    │              │ │ (翻译)     │ │ (打包)     │
    └─────────┬─────┘ └─────┬─────┘ └─────┬─────┘
              │             │             │
              └─────────────┼─────────────┘
                            │
                  ┌─────────▼───────┐
                  │  PostgreSQL     │
                  │  (任务元数据)   │
                  └─────────┬───────┘
                            │
                  ┌─────────▼───────┐
                  │  S3 对象存储    │
                  │ (文件&结果)     │
                  └─────────────────┘
```

### 核心组件详解

#### 1. API 层 (FastAPI)
- **职责**：提供 RESTful 接口，处理用户请求
- **特性**：异步处理、自动文档生成、数据验证
- **部署**：支持多实例负载均衡

#### 2. 任务队列 (Celery + Redis)
- **职责**：异步任务调度和执行
- **特性**：任务优先级、延迟执行、结果缓存
- **扩展性**：支持动态增减 Worker 节点

#### 3. 处理引擎
- **Whisper 转录引擎**：支持 GPU 加速，优先使用 CUDA
- **翻译引擎**：Hugging Face M2M100 或集成 LLM API
- **校验引擎**：Levenshtein 距离算法

#### 4. 存储系统
- **PostgreSQL**：存储任务元数据，支持 JSONB 字段
- **S3 兼容存储**：存储音频、文本和结果文件
- **Redis**：缓存热点数据和任务状态

#### 5. 监控系统
- **Prometheus**：指标收集
- **Grafana**：可视化监控面板
- **日志系统**：结构化日志记录

## 核心业务流程

### 1. 音频处理流程 (AUDIO 来源)

```
用户上传音频 → 创建任务(pending) → 文件上传S3 → 触发STT转录
     ↓
Whisper转录 → 准确性校验 → 状态更新(processing) → 并行翻译任务
     ↓
多语言翻译(标记AUDIO) → 结果收集 → JSON打包 → 上传S3 → 完成(completed)
```

**详细步骤**：
1. **任务创建阶段**
   - 接收音频文件（MP3/WAV）和可选参考文本
   - 生成唯一任务ID (UUID)
   - 存储任务元数据到 PostgreSQL（状态：`pending`）
   - 上传文件到 S3，记录文件路径

2. **STT 转录阶段**
   - Celery Worker 从 Redis 队列获取转录任务
   - 使用 Whisper 模型进行语音转录
   - 更新任务状态为 `processing`
   - 如果有参考文本，使用 Levenshtein 距离计算准确性分数

3. **并行翻译阶段**
   - 为每种目标语言创建独立的翻译任务
   - 并行执行翻译，来源标记为 `AUDIO`
   - 存储翻译结果到临时文件

4. **结果打包阶段**
   - 收集所有翻译结果
   - 生成标准化 JSON 格式文件
   - 上传到 S3 永久存储
   - 更新任务状态为 `completed`

### 2. 文本处理流程 (TEXT 来源)

```
用户上传文本 → 创建任务(pending) → 文件上传S3 → 并行翻译任务
     ↓
多语言翻译(标记TEXT) → 结果收集 → JSON打包 → 上传S3 → 完成(completed)
```

**详细步骤**：
1. **任务创建**：接收文本文件，创建翻译任务
2. **并行翻译**：直接进行多语言翻译，标记来源为 `TEXT`
3. **结果打包**：生成 JSON 文件，包含原始文本和翻译结果

### 3. 查询流程

支持多维度查询：
- **按任务ID查询**：获取任务状态和完整结果
- **按语言+文本编号+来源查询**：快速检索特定翻译结果
- **批量查询**：支持批量获取多个翻译结果

## 技术选型与架构决策

### 编程语言与框架
- **Python 3.9+**：主要开发语言，与 AI 模型生态兼容性最佳
- **FastAPI**：现代异步 Web 框架，高性能、自动文档生成
- **Celery 5.4+**：成熟的分布式任务队列，支持复杂任务编排

### 核心依赖
- **OpenAI Whisper**：业界领先的语音转录模型
- **Hugging Face Transformers**：M2M100 多语言翻译模型
- **PyTorch**：深度学习框架，支持 GPU 加速
- **Textdistance**：文本相似度计算库

### 数据存储
- **PostgreSQL 14+**：主数据库，支持 JSONB 和复杂查询
- **Redis 6+**：消息队列和缓存，高性能键值存储
- **S3 兼容存储**：对象存储，支持大文件和高并发访问

### 基础设施
- **Docker + Kubernetes**：容器化部署，支持自动扩缩容
- **NVIDIA GPU**：优先使用 GPU 加速 Whisper 模型推理
- **Prometheus + Grafana**：监控和告警系统

## 详细实现方案

### 1. 环境搭建与配置

#### Whisper 服务搭建
```bash
# 安装 GPU 版本 PyTorch
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118

# 安装 Whisper
pip install git+https://github.com/openai/whisper.git

# 验证 GPU 可用性
python -c "import torch; print(f'GPU可用: {torch.cuda.is_available()}, 设备数量: {torch.cuda.device_count()}')"

# 测试 Whisper 模型
python -c "import whisper; model = whisper.load_model('medium'); print('Whisper 模型加载成功')"
```

#### Docker 环境配置
```dockerfile
# Dockerfile
FROM nvidia/cuda:11.8-cudnn8-runtime-ubuntu20.04

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    python3 python3-pip ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# 设置工作目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .

# 安装 Python 依赖
RUN pip3 install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY src/ .

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. 核心 API 接口设计

#### 数据模型定义
```python
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from enum import Enum
import uuid

class TaskStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class SourceType(str, Enum):
    AUDIO = "AUDIO"
    TEXT = "TEXT"

class AudioTaskRequest(BaseModel):
    languages: List[str] = Field(..., description="目标翻译语言列表")
    reference_text: Optional[str] = Field(None, description="参考文本用于准确性校验")
    
class TextTaskRequest(BaseModel):
    languages: List[str] = Field(..., description="目标翻译语言列表")
    text_content: str = Field(..., description="待翻译的文本内容")

class TaskResponse(BaseModel):
    task_id: str
    status: TaskStatus
    created_at: str
    languages: List[str]
    accuracy: Optional[float] = None
    error_message: Optional[str] = None
    result_url: Optional[str] = None

class TranslationResult(BaseModel):
    task_id: str
    language: str
    text_id: str
    source: SourceType
    content: str
    accuracy: Optional[float] = None
```

### 3. 主要 API 端点实现

```python
from fastapi import FastAPI, File, UploadFile, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
import logging

app = FastAPI(
    title="VoiceLingua API",
    description="高性能语音转录与多语言翻译系统",
    version="1.0.0"
)

@app.post("/api/v1/tasks/audio", response_model=TaskResponse)
async def create_audio_task(
    audio_file: UploadFile = File(..., description="音频文件 (MP3/WAV)"),
    languages: str = Form(..., description="目标语言列表，逗号分隔"),
    reference_text: Optional[str] = Form(None, description="参考文本")
):
    """
    创建音频转录与翻译任务
    
    支持的音频格式：MP3, WAV, M4A, FLAC
    支持的语言：en, zh, zh-tw, ja, ko, fr, de, es, it, ru
    """
    try:
        # 验证音频文件格式
        if not audio_file.filename.lower().endswith(('.mp3', '.wav', '.m4a', '.flac')):
            raise HTTPException(status_code=400, detail="不支持的音频格式")
        
        # 解析语言列表
        target_languages = [lang.strip() for lang in languages.split(',')]
        
        # 生成任务ID
        task_id = str(uuid.uuid4())
        
        # 保存文件到临时目录
        audio_path = await save_uploaded_file(audio_file, task_id)
        
        # 创建任务记录
        task = await create_task_record(
            task_id=task_id,
            task_type="audio",
            languages=target_languages,
            audio_file=audio_path,
            reference_text=reference_text
        )
        
        # 异步触发转录任务
        transcribe_audio_task.delay(task_id, audio_path, reference_text)
        
        logger.info(f"音频任务创建成功: {task_id}")
        
        return TaskResponse(
            task_id=task_id,
            status=TaskStatus.PENDING,
            created_at=task.created_at.isoformat(),
            languages=target_languages
        )
        
    except Exception as e:
        logger.error(f"创建音频任务失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"任务创建失败: {str(e)}")

@app.get("/api/v1/translations/{language}/{text_id}/{source}", response_model=TranslationResult)
async def get_translation(language: str, text_id: str, source: SourceType):
    """
    按语言、文本编号和来源查询翻译结果
    
    这是系统要求的核心查询接口：通过 语言 -> 文本编号 -> 文本来源 快速查询
    """
    try:
        translation = await get_translation_result(language, text_id, source)
        if not translation:
            raise HTTPException(status_code=404, detail="翻译结果不存在")
        
        return TranslationResult(
            task_id=translation.task_id,
            language=language,
            text_id=text_id,
            source=source,
            content=translation.content,
            accuracy=translation.accuracy
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"查询翻译失败: {str(e)}")
        raise HTTPException(status_code=500, detail=f"查询失败: {str(e)}")
```

### 4. Celery 异步任务实现

#### 转录任务
```python
import whisper
import torch
from textdistance import levenshtein
from celery import current_task

@celery_app.task(bind=True, name='tasks.transcription.transcribe_audio')
def transcribe_audio_task(self, task_id: str, audio_path: str, reference_text: str = None):
    """
    音频转录任务
    
    使用 Whisper 模型进行语音转文本，并计算准确性
    """
    try:
        # 内存检查
        memory_usage = psutil.virtual_memory().percent
        if memory_usage > 80:
            raise Exception(f"内存使用率过高: {memory_usage}%，暂停处理")
        
        # 更新任务状态
        update_task_status(task_id, TaskStatus.PROCESSING, {"message": "开始转录"})
        
        # 加载 Whisper 模型
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model("medium", device=device)
        
        # 执行转录
        logger.info(f"开始转录任务 {task_id}，使用设备: {device}")
        result = model.transcribe(
            audio_path,
            language="zh",  # 可以根据需要调整
            fp16=torch.cuda.is_available(),
            verbose=True
        )
        
        stt_text = result["text"].strip()
        confidence = result.get("confidence", 0.0)
        
        # 准确性校验
        accuracy_score = None
        if reference_text:
            accuracy_score = 1 - levenshtein.normalized_distance(stt_text, reference_text)
            logger.info(f"准确性分数: {accuracy_score:.3f}")
        
        # 保存转录结果
        stt_result = {
            "text": stt_text,
            "confidence": confidence,
            "accuracy": accuracy_score,
            "language": result.get("language", "zh")
        }
        
        save_transcription_result(task_id, stt_result)
        
        # 获取任务的目标语言
        task_info = get_task_by_id(task_id)
        target_languages = task_info.languages
        
        # 触发翻译任务
        for language in target_languages:
            translate_text_task.delay(task_id, stt_text, language, SourceType.AUDIO)
        
        # 如果有参考文本，也进行翻译
        if reference_text:
            for language in target_languages:
                translate_text_task.delay(task_id, reference_text, language, SourceType.TEXT)
        
        logger.info(f"转录任务完成: {task_id}")
        return {"status": "success", "text": stt_text, "accuracy": accuracy_score}
        
    except Exception as e:
        error_msg = f"转录失败: {str(e)}"
        logger.error(f"任务 {task_id} - {error_msg}")
        
        update_task_status(task_id, TaskStatus.FAILED, {"error": error_msg})
        
        # 重试逻辑
        if self.request.retries < self.max_retries:
            logger.info(f"重试转录任务 {task_id} (第 {self.request.retries + 1} 次)")
            raise self.retry(countdown=60, exc=e)
        
        raise e
```

### 5. 数据库设计

#### PostgreSQL 表结构
```sql
-- 任务主表
CREATE TABLE tasks (
    task_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_type VARCHAR(20) NOT NULL, -- 'audio' 或 'text'
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    languages JSONB NOT NULL, -- 目标语言列表
    audio_file_path TEXT,
    text_content TEXT,
    reference_text TEXT,
    accuracy DECIMAL(5,4), -- STT 准确性分数
    error_message TEXT,
    result_url TEXT, -- S3 结果文件路径
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE
);

-- 翻译结果表
CREATE TABLE translation_results (
    id SERIAL PRIMARY KEY,
    task_id UUID NOT NULL REFERENCES tasks(task_id) ON DELETE CASCADE,
    target_language VARCHAR(10) NOT NULL,
    source_type VARCHAR(10) NOT NULL, -- 'AUDIO' 或 'TEXT'
    source_text TEXT NOT NULL,
    translated_text TEXT NOT NULL,
    confidence DECIMAL(5,4),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- 创建唯一索引，支持快速查询
    UNIQUE(task_id, target_language, source_type)
);

-- 创建索引优化查询性能
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_tasks_text_number ON tasks(text_number);
CREATE INDEX idx_translation_results_lookup ON translation_results(target_language, source_type);
```

### 6. 高效数据打包方案

#### JSON 结果格式设计
```json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "task_type": "audio",
  "created_at": "2024-01-01T10:00:00Z",
  "completed_at": "2024-01-01T10:05:30Z",
  "accuracy": 0.95,
  "metadata": {
    "audio_duration": 180.5,
    "audio_format": "mp3",
    "model_version": "whisper-medium",
    "processing_time": 330.2
  },
  "translations": {
    "en": {
      "text": {
        "content": "Hello, this is a transcribed text from audio.",
        "source": "AUDIO",
        "confidence": 0.92,
        "timestamp": "2024-01-01T10:02:15Z"
      },
      "reference_text": {
        "content": "Hello, this is the reference text provided.",
        "source": "TEXT",
        "timestamp": "2024-01-01T10:03:20Z"
      }
    },
    "zh": {
      "text": {
        "content": "你好，这是从音频转录的文本。",
        "source": "AUDIO",
        "confidence": 0.94,
        "timestamp": "2024-01-01T10:02:25Z"
      },
      "reference_text": {
        "content": "你好，这是提供的参考文本。",
        "source": "TEXT",
        "timestamp": "2024-01-01T10:03:30Z"
      }
    }
  },
  "query_index": {
    "by_language": {
      "en": ["text", "reference_text"],
      "zh": ["text", "reference_text"]
    },
    "by_source": {
      "AUDIO": {
        "en": "text",
        "zh": "text"
      },
      "TEXT": {
        "en": "reference_text",
        "zh": "reference_text"
      }
    }
  }
}
```

### 7. 可靠性与扩展性设计

#### 内存监控与负载均衡
```python
import psutil
from typing import Dict, Any

class ResourceMonitor:
    """资源监控器"""
    
    def __init__(self, memory_threshold: float = 80.0, cpu_threshold: float = 90.0):
        self.memory_threshold = memory_threshold
        self.cpu_threshold = cpu_threshold
    
    def check_system_resources(self) -> Dict[str, Any]:
        """检查系统资源使用情况"""
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=1)
        disk = psutil.disk_usage('/')
        
        return {
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "threshold_exceeded": memory.percent > self.memory_threshold
            },
            "cpu": {
                "percent": cpu_percent,
                "threshold_exceeded": cpu_percent > self.cpu_threshold
            },
            "disk": {
                "total": disk.total,
                "free": disk.free,
                "percent": (disk.used / disk.total) * 100
            }
        }
    
    def should_accept_task(self) -> bool:
        """判断是否应该接受新任务"""
        resources = self.check_system_resources()
        
        if resources["memory"]["threshold_exceeded"]:
            logger.warning(f"内存使用率过高: {resources['memory']['percent']:.1f}%")
            return False
        
        if resources["cpu"]["threshold_exceeded"]:
            logger.warning(f"CPU使用率过高: {resources['cpu']['percent']:.1f}%")
            return False
        
        return True
```

## 部署配置

### Docker Compose 配置
```yaml
# docker-compose.yml
version: '3.8'

services:
  # API 服务
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
      - S3_BUCKET=voicelingua-storage
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs

  # Celery Workers
  worker-transcription:
    build: .
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/voicelingua
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    command: celery -A main worker --loglevel=info --queues=transcription --concurrency=2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 数据库
  db:
    image: postgres:14
    environment:
      POSTGRES_DB: voicelingua
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redis
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

## 完整依赖清单

### requirements.txt
```txt
# Web 框架
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# 异步任务
celery[redis]==5.3.4
redis==5.0.1

# 数据库
sqlalchemy==2.0.23
psycopg2-binary==2.9.9

# AI 模型
openai-whisper==20231117
torch==2.1.1
transformers==4.35.2

# 文本处理
textdistance==4.6.1

# 存储和网络
boto3==1.34.0
httpx==0.25.2

# 系统监控
psutil==5.9.6
prometheus-client==0.19.0

# 工具库
pydantic==2.5.0
python-dotenv==1.0.0

# 开发和测试
pytest==7.4.3
pytest-asyncio==0.21.1
```

## 总结

本设计文档详细描述了 VoiceLingua 系统的完整实现方案，充分满足系统设计题目的所有要求：

✅ **环境搭建**：详细的 Whisper 服务搭建和 GPU 优化配置
✅ **服务设计与开发**：完整的 API 接口设计和异步任务处理
✅ **STT 准确性校验**：使用 Levenshtein 距离算法校验转录准确性
✅ **多语言翻译**：支持英语、中文、日语等多种语言并行翻译
✅ **高效数据打包**：紧凑的 JSON 格式，支持快速查询
✅ **快速查询接口**：按语言→文本编号→来源的查询功能
✅ **可靠性设计**：任务重试、故障转移、内存监控
✅ **可扩展性**：支持海量任务和水平扩展

系统采用现代化的微服务架构，能够满足高并发、高可靠性的生产环境需求，为用户提供稳定高效的语音转录和翻译服务。 